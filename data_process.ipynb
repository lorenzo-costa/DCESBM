{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import json\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_name, start, end):\n",
    "    count = 0\n",
    "    data = []\n",
    "    with gzip.open(file_name) as fin:\n",
    "        for l in fin:\n",
    "            count += 1\n",
    "            if count < start:\n",
    "                continue\n",
    "            if count > end:\n",
    "                break\n",
    "            \n",
    "            d = json.loads(l)\n",
    "            data.append(d)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(dir, stop, step):\n",
    "    temp = [0]\n",
    "    start = 0\n",
    "    end = step\n",
    "    out_users = []\n",
    "    out_books = []\n",
    "    count = 0\n",
    "    while count < stop:\n",
    "        temp = load_data(dir, start=start, end = end)\n",
    "        if len(temp) == 0:\n",
    "            break\n",
    "        start = end+1\n",
    "        end = start + step\n",
    "        user_id = []\n",
    "        book_id = []\n",
    "        \n",
    "        for x in temp:\n",
    "            if x['is_read'] is True:\n",
    "                user_id.append(x['user_id'])\n",
    "                book_id.append(x['book_id'])\n",
    "                \n",
    "        out_users.append(Counter(user_id))\n",
    "        out_books.append(Counter(book_id))\n",
    "        count += len(temp)\n",
    "        del temp\n",
    "        del user_id\n",
    "        del book_id\n",
    "        print(count)\n",
    "        \n",
    "    return out_users, out_books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_relevant_ratings(dir, to_take_u, to_take_b, start=0, stop=100, step = 1):\n",
    "    temp = [0]\n",
    "    start = 0\n",
    "    count = 0\n",
    "    end = step\n",
    "    out_ratings = []\n",
    "    out_users = []\n",
    "    out_books = []\n",
    "    while count < stop:\n",
    "        temp = load_data(dir, start=start, end = end)\n",
    "        \n",
    "        if len(temp) == 0:\n",
    "            break\n",
    "        start = end+1\n",
    "        end = start + step\n",
    "        \n",
    "        for x in temp:\n",
    "            if x['is_read'] is True:\n",
    "                if x['user_id'] in to_take_u and x['book_id'] in to_take_b:\n",
    "                    out_ratings.append(x['rating'])\n",
    "                    out_users.append(x['user_id'])\n",
    "                    out_books.append(x['book_id'])\n",
    "    \n",
    "        count += len(temp)\n",
    "        del temp\n",
    "        print(count)\n",
    "        \n",
    "    return out_ratings, out_users, out_books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_books(dir, to_take, start, stop, step):\n",
    "    temp = [0]\n",
    "    start = 0\n",
    "    count = 0\n",
    "    end = step\n",
    "    out = []\n",
    "    out_book_id = []\n",
    "    out_description = []\n",
    "    out_work_id = []\n",
    "    while count < stop:\n",
    "        temp = load_data(dir, start=start, end = end)\n",
    "        \n",
    "        if len(temp) == 0:\n",
    "            break\n",
    "        start = end+1\n",
    "        end = start + step\n",
    "        \n",
    "        for x in temp:\n",
    "            if x['book_id'] in to_take:\n",
    "                out.append(x)\n",
    "                out_book_id.append(x['book_id'])\n",
    "                out_description.append(x['description'])\n",
    "                out_work_id.append(x['work_id'])\n",
    "    \n",
    "        count += len(temp)\n",
    "        del temp\n",
    "        print(count)\n",
    "        \n",
    "    return out, out_book_id, out_description, out_work_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR = 'goodreadsdata/goodreads_books.json.gz' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m out_users, out_books = \u001b[43mprocess_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDIR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1e8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m4e6\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m out_users_cum = Counter()\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m out_users:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 9\u001b[39m, in \u001b[36mprocess_data\u001b[39m\u001b[34m(dir, stop, step)\u001b[39m\n\u001b[32m      7\u001b[39m count = \u001b[32m0\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m count < stop:\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     temp = \u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mdir\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(temp) == \u001b[32m0\u001b[39m:\n\u001b[32m     11\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36mload_data\u001b[39m\u001b[34m(file_name, start, end)\u001b[39m\n\u001b[32m      3\u001b[39m data = []\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m gzip.open(file_name) \u001b[38;5;28;01mas\u001b[39;00m fin:\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ml\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfin\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcount\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\n\u001b[32m      7\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcount\u001b[49m\u001b[43m \u001b[49m\u001b[43m<\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/thesisenv/lib/python3.13/gzip.py:446\u001b[39m, in \u001b[36mGzipFile.readline\u001b[39m\u001b[34m(self, size)\u001b[39m\n\u001b[32m    444\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mreadline\u001b[39m(\u001b[38;5;28mself\u001b[39m, size=-\u001b[32m1\u001b[39m):\n\u001b[32m    445\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_not_closed()\n\u001b[32m--> \u001b[39m\u001b[32m446\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_buffer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/thesisenv/lib/python3.13/_compression.py:68\u001b[39m, in \u001b[36mDecompressReader.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mreadinto\u001b[39m(\u001b[38;5;28mself\u001b[39m, b):\n\u001b[32m     67\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mmemoryview\u001b[39m(b) \u001b[38;5;28;01mas\u001b[39;00m view, view.cast(\u001b[33m\"\u001b[39m\u001b[33mB\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m byte_view:\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m         data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbyte_view\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     69\u001b[39m         byte_view[:\u001b[38;5;28mlen\u001b[39m(data)] = data\n\u001b[32m     70\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/thesisenv/lib/python3.13/gzip.py:556\u001b[39m, in \u001b[36m_GzipReader.read\u001b[39m\u001b[34m(self, size)\u001b[39m\n\u001b[32m    554\u001b[39m     uncompress = \u001b[38;5;28mself\u001b[39m._decompressor.decompress(buf, size)\n\u001b[32m    555\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m556\u001b[39m     uncompress = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_decompressor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecompress\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    558\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._decompressor.unused_data != \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    559\u001b[39m     \u001b[38;5;66;03m# Prepend the already read bytes to the fileobj so they can\u001b[39;00m\n\u001b[32m    560\u001b[39m     \u001b[38;5;66;03m# be seen by _read_eof() and _read_gzip_header()\u001b[39;00m\n\u001b[32m    561\u001b[39m     \u001b[38;5;28mself\u001b[39m._fp.prepend(\u001b[38;5;28mself\u001b[39m._decompressor.unused_data)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "out_users, out_books = process_data(DIR, stop=1e8, step = 4e6)\n",
    "out_users_cum = Counter()\n",
    "for x in out_users:\n",
    "    out_users_cum = out_users_cum+x\n",
    "\n",
    "out_books_cum = Counter()\n",
    "for x in out_books:\n",
    "    out_books_cum = out_books_cum+x\n",
    "    \n",
    "# with open(\"user_counts.json\", \"w\") as f:\n",
    "#     json.dump(dict(out_users_cum), f)\n",
    "    \n",
    "# with open(\"book_counts.json\", \"w\") as f:\n",
    "#     json.dump(dict(out_books_cum), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('user_counts.json') as f:\n",
    "#     dt_users = json.load(f)\n",
    "\n",
    "# dt_users = Counter(dt_users)\n",
    "\n",
    "# with open('book_counts.json') as f:\n",
    "#     dt_books = json.load(f)\n",
    "\n",
    "# dt_books = Counter(dt_books)\n",
    "\n",
    "# top_users = dict(dt_users.most_common(5000))\n",
    "# top_books = dict(dt_books.most_common(5000))\n",
    "\n",
    "# top_users_id = list(top_users.keys())\n",
    "# top_books_id = list(top_books.keys())\n",
    "\n",
    "# r, u, b = find_relevant_ratings(DIR, top_users_id, top_books_id, start=0, stop=1e8, step = 1e6)\n",
    "\n",
    "# with open('ratings.json','w') as f:\n",
    "#     json.dump(a, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out, out_book_id, out_description, out_work_id = process_books(DIR, top_books_id, start=0, stop=1e8, step=1e5)\n",
    "\n",
    "# with open('book_info.json', 'w') as f:\n",
    "#     json.dump([out, out_book_id, out_description, out_work_id], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('user_counts.json') as f:\n",
    "    dt_users = json.load(f)\n",
    "\n",
    "dt_users = Counter(dt_users)\n",
    "\n",
    "with open('book_counts.json') as f:\n",
    "    dt_books = json.load(f)\n",
    "\n",
    "dt_books = Counter(dt_books)\n",
    "\n",
    "top_users = dict(dt_users.most_common(5000))\n",
    "top_books = dict(dt_books.most_common(5000))\n",
    "\n",
    "top_users_id = list(top_users.keys())\n",
    "top_books_id = list(top_books.keys())\n",
    "\n",
    "with open('ratings.json') as f:\n",
    "    ratings_data = json.load(f)\n",
    "\n",
    "with open('book_info.json') as f:\n",
    "    book_info = json.load(f)\n",
    "\n",
    "book_info_id = book_info[1]\n",
    "book_info_description = book_info[2]\n",
    "book_info_word_id = book_info[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "link = book_info[0][0]['link']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URL of the book page\n",
    "url = \"https://www.goodreads.com/book/show/54270.Mein_Kampf\"\n",
    "\n",
    "# Make a request to fetch the page content\n",
    "headers = {'User-Agent': 'Mozilla/5.0'}  # Goodreads may block bot-like requests without headers\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "# Parse the HTML\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Find all the genre spans\n",
    "genre_spans = soup.find_all('span', class_='BookPageMetadataSection__genreButton')\n",
    "\n",
    "# Extract the text of each genre\n",
    "genres = [span.get_text(strip=True) for span in genre_spans]\n",
    "\n",
    "# Print the genres\n",
    "print(genre_spans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_genres(book_list):\n",
    "    genres = []\n",
    "    for book in book_list:\n",
    "        url = book['link']\n",
    "        headers = {'User-Agent': 'Mozilla/5.0'}  # Goodreads may block bot-like requests without headers\n",
    "        response = requests.get(url, headers=headers)\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "        genre_spans = soup.find_all('span', class_='BookPageMetadataSection__genreButton')\n",
    "        if len(genre_spans) == 0:\n",
    "            print(url)\n",
    "        genres.append([span.get_text(strip=True) for span in genre_spans])\n",
    "    return genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import concurrent.futures\n",
    "import time # To demonstrate speedup\n",
    "\n",
    "def fetch_and_parse_genres(book):\n",
    "    \"\"\"Fetches and parses genres for a single book's URL.\"\"\"\n",
    "    url = book.get('link')\n",
    "    if not url:\n",
    "        print(\"Warning: Book entry missing 'link'\")\n",
    "        return [] # Return empty list if no link\n",
    "\n",
    "    headers = {'User-Agent': 'Mozilla/5.0'} # Be a good citizen\n",
    "    genres_for_book = []\n",
    "    try:\n",
    "        # Consider adding a timeout\n",
    "        response = requests.get(url, headers=headers, timeout=15)\n",
    "        response.raise_for_status() # Raise an exception for bad status codes (4xx or 5xx)\n",
    "\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "        # Updated selector based on potential Goodreads changes (check current site structure)\n",
    "        # Common patterns: data-testid=\"genres\" or specific class names\n",
    "        genre_elements = soup.select('a[href*=\"/genres/\"]') # Example selector, ADJUST AS NEEDED\n",
    "        \n",
    "        # If the above doesn't work, revert to original or inspect the page source:\n",
    "        if not genre_elements:\n",
    "             genre_spans = soup.find_all('span', class_='BookPageMetadataSection__genreButton') # Original selector\n",
    "             genres_for_book = [span.get_text(strip=True) for span in genre_spans]\n",
    "        else:\n",
    "             # Process the elements found by the selector\n",
    "             # This might need adjustment depending on the exact HTML structure\n",
    "             genres_for_book = [elem.get_text(strip=True) for elem in genre_elements if '/genres/' in elem.get('href', '')]\n",
    "             # Simple deduplication if needed\n",
    "             genres_for_book = list(dict.fromkeys(genres_for_book))\n",
    "\n",
    "\n",
    "        if not genres_for_book:\n",
    "            print(f\"Warning: No genres found for {book.get('title'), url}\")\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching {url}: {e}\")\n",
    "        # Decide how to handle errors: return empty list, None, or raise exception\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing {url}: {e}\")\n",
    "        return [] # Return empty list on parsing error\n",
    "\n",
    "    return genres_for_book\n",
    "\n",
    "# --- Parallel execution function ---\n",
    "def find_genres_parallel(book_list, max_workers=10):\n",
    "    \"\"\"Finds genres for a list of books in parallel using threads.\"\"\"\n",
    "    all_genres = []\n",
    "    # Use ThreadPoolExecutor to manage threads\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        # map applies the function to each item in book_list concurrently\n",
    "        # It returns results in the order the tasks were submitted\n",
    "        results = executor.map(fetch_and_parse_genres, book_list)\n",
    "        all_genres = list(results) # Convert the iterator to a list\n",
    "\n",
    "    return all_genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: No genres found for ('Mein Kampf', 'https://www.goodreads.com/book/show/54270.Mein_Kampf')\n",
      "Warning: No genres found for ('كفاحي', 'https://www.goodreads.com/book/show/3947919')\n",
      "Warning: No genres found for ('The Constitution of the United States of America', 'https://www.goodreads.com/book/show/89959.The_Constitution_of_the_United_States_of_America')\n",
      "Warning: No genres found for (\"The Three Musketeers (The D'Artagnan Romances, #1)\", 'https://www.goodreads.com/book/show/7190.The_Three_Musketeers')\n"
     ]
    }
   ],
   "source": [
    "genres = find_genres_parallel(book_info[0], max_workers=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- find most commonly used books\n",
    "- extract descriptions\n",
    "- merge indices for same books using the works list i.e. if two books have the same work_id aggregate the ratings for those by picking only one of the ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\costa\\anaconda3\\Lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dt = pd.DataFrame({'rating':ratings_data[0], 'user_id':ratings_data[1], 'book_id':ratings_data[2]})\n",
    "other_dt = pd.DataFrame({'book_id':book_info_id, 'work_id':book_info_word_id, 'description':book_info_description, 'genres':genres})\n",
    "temp = pd.merge(dt, other_dt, how='left', on='book_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_work_ids = temp.groupby('work_id')['book_id'].nunique()\n",
    "duplicate_work_ids = duplicate_work_ids[duplicate_work_ids > 1]\n",
    "\n",
    "result = temp[temp['work_id'].isin(duplicate_work_ids.index)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_data = load_data('goodreads_book_works.json.gz', 0, 1e8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_id_title = {x['work_id']:x['original_title'] for x in work_data}\n",
    "work_id_best_book_id = {x['work_id']:x['best_book_id'] for x in work_data}\n",
    "work_id_pub_year = {x['work_id']:x['original_publication_year'] for x in work_data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp['book_id'] = temp.apply(lambda row: work_id_best_book_id.get(row['work_id'], row['book_id']), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp['title'] = temp.apply(lambda row: work_id_title.get(row['work_id']), axis = 1)\n",
    "temp['title'] = temp['title'].apply(lambda x: 'missing' if len(x)==0 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp['year_pub'] = temp.apply(lambda row: work_id_pub_year.get(row['work_id'], 'missing'), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp['romance'] = temp['genres'].apply(lambda x: 1 if len(set(x).intersection(['Romance', 'romance']))>0 else 0)\n",
    "temp['history'] = temp['genres'].apply(lambda x: 1 if len(set(x).intersection(['History', 'history']))>0 else 0)\n",
    "\n",
    "temp['biography'] = temp['genres'].apply(lambda x: 1 if len(set(x).intersection(['Biography', 'biography', 'Autobiography']))>0 else 0)\n",
    "\n",
    "temp['fantasy'] = temp['genres'].apply(lambda x: 1 if len(set(x).intersection(['Fantasy', 'fantasy']))>0 else 0)\n",
    "\n",
    "temp['fiction'] = temp['genres'].apply(lambda x: 1 if len(set(x).intersection(['Fiction', 'fiction']))>0 else 0)\n",
    "\n",
    "temp['mistery'] = temp['genres'].apply(lambda x: 1 if len(set(x).intersection(['Mystery', 'mystery']))>0 else 0)\n",
    "\n",
    "temp['classic'] = temp['genres'].apply(lambda x: 1 if len(set(x).intersection(['Classic', 'classic', 'Classics', 'classics']))>0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1', '2'}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = ['1', '2']\n",
    "b = ['1', '2', '3', '4']\n",
    "set(a).intersection(b) # {'1', '2'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_clean = temp.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_clean.to_csv('dataset_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_form = dataset_clean.pivot_table(index='user_id', columns='book_id', values='rating', fill_value=0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_clean = pd.read_csv('dataset_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>user_id</th>\n",
       "      <th>book_id</th>\n",
       "      <th>work_id</th>\n",
       "      <th>description</th>\n",
       "      <th>genres</th>\n",
       "      <th>title</th>\n",
       "      <th>year_pub</th>\n",
       "      <th>romance</th>\n",
       "      <th>history</th>\n",
       "      <th>biography</th>\n",
       "      <th>young_adult</th>\n",
       "      <th>fantasy</th>\n",
       "      <th>fiction</th>\n",
       "      <th>mystery</th>\n",
       "      <th>classic</th>\n",
       "      <th>mistery</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>467ed8f03548be6c2d9228f9a2f7b2ea</td>\n",
       "      <td>32860355</td>\n",
       "      <td>53464530</td>\n",
       "      <td>Their romance shaped a nation. The rest was hi...</td>\n",
       "      <td>[Historical Fiction, Romance, Young Adult, His...</td>\n",
       "      <td>Alex and Eliza</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>467ed8f03548be6c2d9228f9a2f7b2ea</td>\n",
       "      <td>33607640</td>\n",
       "      <td>54427214</td>\n",
       "      <td>Fiona Davis, author of The Dollhouse, returns ...</td>\n",
       "      <td>[Historical Fiction, Fiction, Mystery, Histori...</td>\n",
       "      <td>missing</td>\n",
       "      <td>2017</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>467ed8f03548be6c2d9228f9a2f7b2ea</td>\n",
       "      <td>27833796</td>\n",
       "      <td>47815738</td>\n",
       "      <td>The miraculous new novel from New York Times-b...</td>\n",
       "      <td>[Fiction, Historical Fiction, France, Book Clu...</td>\n",
       "      <td>The Light of Paris</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>467ed8f03548be6c2d9228f9a2f7b2ea</td>\n",
       "      <td>30555488</td>\n",
       "      <td>48287641</td>\n",
       "      <td>Cora is a slave on a cotton plantation in Geor...</td>\n",
       "      <td>[Historical Fiction, Fiction, Book Club, Histo...</td>\n",
       "      <td>The Underground Railroad</td>\n",
       "      <td>2016</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>467ed8f03548be6c2d9228f9a2f7b2ea</td>\n",
       "      <td>29430012</td>\n",
       "      <td>45743836</td>\n",
       "      <td>From the New York Timesbestselling author of \u0001...</td>\n",
       "      <td>[Historical Fiction, Fiction, Book Club, Histo...</td>\n",
       "      <td>A Gentleman in Moscow</td>\n",
       "      <td>2016</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating                           user_id   book_id   work_id  \\\n",
       "0       4  467ed8f03548be6c2d9228f9a2f7b2ea  32860355  53464530   \n",
       "1       4  467ed8f03548be6c2d9228f9a2f7b2ea  33607640  54427214   \n",
       "2       4  467ed8f03548be6c2d9228f9a2f7b2ea  27833796  47815738   \n",
       "3       4  467ed8f03548be6c2d9228f9a2f7b2ea  30555488  48287641   \n",
       "4       5  467ed8f03548be6c2d9228f9a2f7b2ea  29430012  45743836   \n",
       "\n",
       "                                         description  \\\n",
       "0  Their romance shaped a nation. The rest was hi...   \n",
       "1  Fiona Davis, author of The Dollhouse, returns ...   \n",
       "2  The miraculous new novel from New York Times-b...   \n",
       "3  Cora is a slave on a cotton plantation in Geor...   \n",
       "4  From the New York Timesbestselling author of \u0001...   \n",
       "\n",
       "                                              genres  \\\n",
       "0  [Historical Fiction, Romance, Young Adult, His...   \n",
       "1  [Historical Fiction, Fiction, Mystery, Histori...   \n",
       "2  [Fiction, Historical Fiction, France, Book Clu...   \n",
       "3  [Historical Fiction, Fiction, Book Club, Histo...   \n",
       "4  [Historical Fiction, Fiction, Book Club, Histo...   \n",
       "\n",
       "                      title year_pub  romance  history  biography  \\\n",
       "0            Alex and Eliza     2017        1        0          0   \n",
       "1                   missing     2017        0        0          0   \n",
       "2        The Light of Paris     2016        1        0          0   \n",
       "3  The Underground Railroad     2016        0        0          0   \n",
       "4     A Gentleman in Moscow     2016        0        0          0   \n",
       "\n",
       "   young_adult  fantasy  fiction  mystery  classic  mistery  \n",
       "0            1        0        1        0        0        0  \n",
       "1            0        0        1        1        0        1  \n",
       "2            0        0        1        0        0        0  \n",
       "3            0        0        1        0        0        0  \n",
       "4            0        0        1        0        0        0  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres_list = load_data('goodreads_books.json.gz', 0, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'isbn': '0312853122',\n",
       " 'text_reviews_count': '1',\n",
       " 'series': [],\n",
       " 'country_code': 'US',\n",
       " 'language_code': '',\n",
       " 'popular_shelves': [{'count': '3', 'name': 'to-read'},\n",
       "  {'count': '1', 'name': 'p'},\n",
       "  {'count': '1', 'name': 'collection'},\n",
       "  {'count': '1', 'name': 'w-c-fields'},\n",
       "  {'count': '1', 'name': 'biography'}],\n",
       " 'asin': '',\n",
       " 'is_ebook': 'false',\n",
       " 'average_rating': '4.00',\n",
       " 'kindle_asin': '',\n",
       " 'similar_books': [],\n",
       " 'description': '',\n",
       " 'format': 'Paperback',\n",
       " 'link': 'https://www.goodreads.com/book/show/5333265-w-c-fields',\n",
       " 'authors': [{'author_id': '604031', 'role': ''}],\n",
       " 'publisher': \"St. Martin's Press\",\n",
       " 'num_pages': '256',\n",
       " 'publication_day': '1',\n",
       " 'isbn13': '9780312853129',\n",
       " 'publication_month': '9',\n",
       " 'edition_information': '',\n",
       " 'publication_year': '1984',\n",
       " 'url': 'https://www.goodreads.com/book/show/5333265-w-c-fields',\n",
       " 'image_url': 'https://images.gr-assets.com/books/1310220028m/5333265.jpg',\n",
       " 'book_id': '5333265',\n",
       " 'ratings_count': '3',\n",
       " 'work_id': '5400751',\n",
       " 'title': 'W.C. Fields: A Life on Film',\n",
       " 'title_without_series': 'W.C. Fields: A Life on Film'}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genres_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genres_list_to_dict(genres_list):\n",
    "    genres_dict = {}\n",
    "    for x in genres_list:\n",
    "        genres_dict[x['book_id']] = x['genres']\n",
    "    return genres_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_dict = genres_list_to_dict(genres_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_clean['genres'] = dataset_clean['book_id'].map(genre_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>rating</th>\n",
       "      <th>user_id</th>\n",
       "      <th>book_id</th>\n",
       "      <th>work_id</th>\n",
       "      <th>description</th>\n",
       "      <th>title</th>\n",
       "      <th>year_pub</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Unnamed: 0, rating, user_id, book_id, work_id, description, title, year_pub, genres]\n",
       "Index: []"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_clean[~dataset_clean['genres'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in genres_list:\n",
    "    if x['book_id'] in dataset_clean['book_id'].values:\n",
    "        print(x['book_id'])\n",
    "        print(x['genres'])\n",
    "        print('---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesisenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
